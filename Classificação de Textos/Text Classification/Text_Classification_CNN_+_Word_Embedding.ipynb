{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_CNN_+_Word_Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importando as bibliotecas**"
      ],
      "metadata": {
        "id": "-rawxNxLTM2l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a6-j7FpVyalE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Leitura da base de Dados**"
      ],
      "metadata": {
        "id": "bI-zGFmVTRXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Corpus_processado2.csv', sep=';', encoding='latin-1')\n",
        "dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70qvu-vHyh8h",
        "outputId": "19584ca8-2186-4e6d-a0af-cfb7dcd4a2f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 399 entries, 0 to 398\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Abstract  399 non-null    object\n",
            " 1   Classe    399 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 6.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = ['antitumorpromot principl angelica keiskei potent antitumor promot activ nonpolar extract root ashitaba angelica keiskei koidz umbellifera eaten veget japan activ fraction angular furanocoumarin archangelicin sr angeloyloxydihydrooroselol linear furanocoumarin psoralen bergapten xanthotoxin chalcon hydroxyderricin xanthoangelol novel chalcon name ashitabachalcon isol compound angular type furanocoumarin chalcon suppress otetradecanoylphorbolacet tpa piincorpor phospholipid cultur cell coumarin less effect addit chalcon prove antitumorpromot activ mous skin carcinogenesi induc dimethylbenz anthracen dmba plus tpa chalcon calmodulininteract properti chalcon reveal antitumorpromot activ via modul calmodulin involv system chalcon effect prevent']"
      ],
      "metadata": {
        "id": "aaXXiy1NywR_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Count Vectorizer**\n",
        "\n",
        "\n",
        "Scikit-learn's CountVectorizer é utilizado para converter uma colecção de documentos de texto para um vector de contagem de termos/token. Também permite o pré-processamento de dados de texto antes de gerar a representação vectorial. Esta funcionalidade torna-o um módulo de representação de características altamente flexível para texto."
      ],
      "metadata": {
        "id": "cEjMhCawTXtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "examplevectorizer = CountVectorizer()\n",
        "examplevectorizer.fit(example)\n",
        "examplevectorizer.vocabulary_ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APKbr7HvzAx6",
        "outputId": "548eef23-9093-4804-ad4f-bec876f342f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activ': 0,\n",
              " 'addit': 1,\n",
              " 'angelica': 2,\n",
              " 'angeloyloxydihydrooroselol': 3,\n",
              " 'angular': 4,\n",
              " 'anthracen': 5,\n",
              " 'antitumor': 6,\n",
              " 'antitumorpromot': 7,\n",
              " 'archangelicin': 8,\n",
              " 'ashitaba': 9,\n",
              " 'ashitabachalcon': 10,\n",
              " 'bergapten': 11,\n",
              " 'calmodulin': 12,\n",
              " 'calmodulininteract': 13,\n",
              " 'carcinogenesi': 14,\n",
              " 'cell': 15,\n",
              " 'chalcon': 16,\n",
              " 'compound': 17,\n",
              " 'coumarin': 18,\n",
              " 'cultur': 19,\n",
              " 'dimethylbenz': 20,\n",
              " 'dmba': 21,\n",
              " 'eaten': 22,\n",
              " 'effect': 23,\n",
              " 'extract': 24,\n",
              " 'fraction': 25,\n",
              " 'furanocoumarin': 26,\n",
              " 'hydroxyderricin': 27,\n",
              " 'induc': 28,\n",
              " 'involv': 29,\n",
              " 'isol': 30,\n",
              " 'japan': 31,\n",
              " 'keiskei': 32,\n",
              " 'koidz': 33,\n",
              " 'less': 34,\n",
              " 'linear': 35,\n",
              " 'modul': 36,\n",
              " 'mous': 37,\n",
              " 'name': 38,\n",
              " 'nonpolar': 39,\n",
              " 'novel': 40,\n",
              " 'otetradecanoylphorbolacet': 41,\n",
              " 'phospholipid': 42,\n",
              " 'piincorpor': 43,\n",
              " 'plus': 44,\n",
              " 'potent': 45,\n",
              " 'prevent': 46,\n",
              " 'principl': 47,\n",
              " 'promot': 48,\n",
              " 'properti': 49,\n",
              " 'prove': 50,\n",
              " 'psoralen': 51,\n",
              " 'reveal': 52,\n",
              " 'root': 53,\n",
              " 'skin': 54,\n",
              " 'sr': 55,\n",
              " 'suppress': 56,\n",
              " 'system': 57,\n",
              " 'tpa': 58,\n",
              " 'type': 59,\n",
              " 'umbellifera': 60,\n",
              " 'veget': 61,\n",
              " 'via': 62,\n",
              " 'xanthoangelol': 63,\n",
              " 'xanthotoxin': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformação em Array**"
      ],
      "metadata": {
        "id": "zOPSu7j9T-N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examplevectorizer.transform(example).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieVwKPSczIZr",
        "outputId": "59a97a66-d226-48eb-fecb-85016c99171d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4, 1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1,\n",
              "        1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Divisão de Treino e Teste**"
      ],
      "metadata": {
        "id": "y4NWIsLxUDtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "review = dataset['Abstract'].values\n",
        "label = dataset['Classe'].values\n",
        "review_train, review_test, label_train, label_test = train_test_split(\n",
        "review, label, test_size=0.25, random_state=1000) "
      ],
      "metadata": {
        "id": "SXfi2B_0zLS5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "review_vectorizer = CountVectorizer()\n",
        "review_vectorizer.fit(review_train)\n",
        "Xlr_train = review_vectorizer.transform(review_train)\n",
        "Xlr_test  = review_vectorizer.transform(review_test)\n",
        "Xlr_train "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgUrXqT1zh6q",
        "outputId": "ad1d34b2-fd69-4921-877c-1dcb687cba3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<299x5803 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 20604 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regressão Logística**"
      ],
      "metadata": {
        "id": "yM1vl8pmUMZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LRmodel = LogisticRegression()\n",
        "LRmodel.fit(Xlr_train, label_train)\n",
        "score = LRmodel.score(Xlr_test, label_test)\n",
        "print(\"Accuracy:\", score) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHEVUtPHzl_X",
        "outputId": "f9b98c68-544f-45ca-ba47-d0fc2afe30b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(review_train)\n",
        "Xcnn_train = tokenizer.texts_to_sequences(review_train)\n",
        "Xcnn_test = tokenizer.texts_to_sequences(review_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1  \n",
        "print(review_train[1])\n",
        "print(Xcnn_train[1]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6fEVY0TzrDW",
        "outputId": "21166e4e-0209-440a-94de-9a5d8b65cae5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "periop anesthesia care narrat review discuss uptod focus avail best clinic practic periop anesthesia care bundl effect main object apprais literatur local anesthet region outcom opioid nonsteroid antiinflammatori nsaid abil decreas recurr patient undergo surgeri brief discuss addit topic periop relev anesthesiologist volatil intraven anesthet periop anxieti nutrit result publish systemat review look associ recurr region anesthesia yield inconclus insuffici evid definit benefit region anesthesia basic scienc anti effect induc local anesthet new refin anim model opioid safe periop pain manag preliminari evid nsaid essenti multimod analgesia volatil anesthet format preclin clinic propofol indic protect qualiti periop period patient uniqu environ where surgic mediat lead suppress region anesthesia techniqu indic multimod analgesia nsaid opioid local anesthet prevent pathophysiolog effect pain neuroendocrin view essenti balanc anesthesia\n",
            "[702, 128, 504, 2332, 92, 284, 2333, 503, 206, 636, 85, 909, 702, 128, 504, 2334, 3, 225, 910, 2335, 703, 377, 207, 199, 251, 1250, 285, 68, 121, 234, 28, 103, 9, 436, 113, 1821, 284, 55, 3338, 702, 326, 3339, 1475, 704, 207, 702, 3340, 505, 10, 1052, 564, 92, 2336, 15, 103, 199, 128, 566, 2337, 1822, 45, 1823, 235, 199, 128, 1251, 1824, 2338, 3, 4, 377, 207, 96, 3341, 208, 97, 1250, 637, 702, 1252, 808, 1053, 45, 121, 809, 2339, 1054, 1475, 207, 236, 506, 85, 107, 44, 161, 1055, 702, 269, 9, 705, 908, 378, 327, 147, 116, 46, 199, 128, 69, 44, 2339, 1054, 121, 1250, 377, 207, 65, 3342, 3, 1252, 2340, 1476, 809, 1477, 128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = 100\n",
        "Xcnn_train = pad_sequences(Xcnn_train, padding='post', maxlen=maxlen)\n",
        "Xcnn_test = pad_sequences(Xcnn_test, padding='post', maxlen=maxlen)\n",
        "print(Xcnn_train[0, :]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ttg9PP-zxd8",
        "outputId": "e3a20bdc-f506-4f11-8151-0092b1d30c0a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 189  564   92  565  907 1471   53    2    7  299 1248  908  375   53\n",
            "    7 1471 3334   65  146   43  283   11  223   13  435  221  102 2330\n",
            "  223 2329 1472   93 1818 1473  564   92  565    3 1472  102   20 2331\n",
            "    1  138   41 3335  701 1249 3336   53   83  160    1  189    1   12\n",
            "    3 1050 1819 1051  181  153    3 1472  189    1 1819  325  351  503\n",
            "  376  102 1819  325  351    3  283   11 1472  102    3 2331    1 1049\n",
            "  222   53    7  166  907  131  268 1820   19   84  635  462  352 3337\n",
            " 1474  224]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers "
      ],
      "metadata": {
        "id": "aS7DMJKBz1GE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criando o Modelo da CNN**"
      ],
      "metadata": {
        "id": "fvtvd_8IUUJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 200\n",
        "textcnnmodel = Sequential()\n",
        "textcnnmodel.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "textcnnmodel.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "textcnnmodel.add(layers.GlobalMaxPooling1D())\n",
        "textcnnmodel.add(layers.Dense(10, activation='relu'))\n",
        "textcnnmodel.add(layers.Dense(1, activation='sigmoid'))\n",
        "textcnnmodel.compile(optimizer='adam',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "textcnnmodel.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLBD0vAhz34k",
        "outputId": "dd422d04-2ab4-4b7f-c819-623eeca2d917"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 200)          1161400   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 128)           128128    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,290,829\n",
            "Trainable params: 1,290,829\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Acurácia**"
      ],
      "metadata": {
        "id": "gJs6u8i_UZbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textcnnmodel.fit(Xcnn_train, label_train,\n",
        "                     epochs=30,\n",
        "                     verbose=False,\n",
        "                     validation_data=(Xcnn_test, label_test),\n",
        "                     batch_size=10)\n",
        "loss, accuracy = textcnnmodel.evaluate(Xcnn_train, label_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = textcnnmodel.evaluate(Xcnn_test, label_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mliOHHJ3z_TY",
        "outputId": "36c12310-9c2e-44f2-fb26-402cc153bb46"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0000\n",
            "Testing Accuracy:  0.9500\n"
          ]
        }
      ]
    }
  ]
}